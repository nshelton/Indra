#version 450 core

layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;

// ============================================================================
// Buffers and Textures
// ============================================================================

// Depth input (from raymarching passes)
layout(rgba16f, binding = 0) readonly uniform image2D u_thisFrameShaded;
layout(rgba16f, binding = 1) readonly uniform image2D u_lastFrameShaded;

// Color output
layout(rgba16f, binding = 2) writeonly uniform image2D uColorOutput;

// ============================================================================
// Uniforms
// ============================================================================

// Viewport
uniform int uViewportWidth;
uniform int uViewportHeight;
uniform vec3 uCameraPos;
uniform vec3 uCameraForward;
uniform vec3 uCameraRight;
uniform vec3 uCameraUp;
uniform float uTanHalfFov;
uniform float uAspect;

vec3 computeRayDirection(ivec2 pixel, ivec2 resolution) {
    vec2 uv = (vec2(pixel) + vec2(0.5)) / vec2(resolution);
    float ndcX = uv.x * 2.0 - 1.0;
    float ndcY = 1.0 - uv.y * 2.0;

    return normalize( vec3(
        ndcX * uTanHalfFov * uAspect,
        -ndcY * uTanHalfFov,
        -1
    ));
}

vec2 projectToPixel(vec3 localPos, ivec2 resolution) {
    // Transform world position to camera/view space
    // Perspective divide
    float ndcX = -localPos.x / (localPos.z * uTanHalfFov * uAspect);
    float ndcY = localPos.y / (localPos.z * uTanHalfFov);
    // NDC to UV to pixel
    vec2 uv = vec2(
        (ndcX + 1.0) * 0.5,
        (1.0 - ndcY) * 0.5
    );
    return uv * vec2(resolution) - 0.5;
}

uniform mat4 uThisFrameToLastFrame;

void main()
{
    ivec2 pixel = ivec2(gl_GlobalInvocationID.xy);
    ivec2 resolution = imageSize(uColorOutput);

    if (pixel.x >= resolution.x || pixel.y >= resolution.y) {
        return;
    }

    vec4 current = imageLoad(u_thisFrameShaded, pixel);

    // Transform to NDC
    vec4 ndcThisFrame = vec4(
        (float(pixel.x) + 0.5) / float(uViewportWidth) * 2.0 - 1.0,
        (float(pixel.y) + 0.5) / float(uViewportHeight) * 2.0 - 1.0,
        current.a * 2.0 - 1.0,
        1.0
    );

    // Reproject to last frame
    vec3 thisFrameCamPos = computeRayDirection(pixel, resolution) * current.a;

    vec3 lastFrameCameraPos = (uThisFrameToLastFrame * vec4(thisFrameCamPos, 1.0)).xyz;

    vec2 lastPixel = projectToPixel(lastFrameCameraPos, resolution);

    // Bounds check
    if (lastPixel.x < 0.0 || lastPixel.x > float(resolution.x) ||
        lastPixel.y < 0.0 || lastPixel.y > float(resolution.y)) {
        imageStore(uColorOutput, pixel, current);
        return;
    }
    ivec2 lastPixelInt = ivec2(floor(lastPixel));
    vec2 fract = lastPixel - vec2(lastPixelInt);
    // Convert UV to pixel coordinates (for bilinear interpolation)

    // // Bilinear sample (manual since using images)
    vec4 s00 = imageLoad(u_lastFrameShaded, lastPixelInt + ivec2(0, 0));
    vec4 s10 = imageLoad(u_lastFrameShaded, lastPixelInt + ivec2(1, 0));
    vec4 s01 = imageLoad(u_lastFrameShaded, lastPixelInt + ivec2(0, 1));
    vec4 s11 = imageLoad(u_lastFrameShaded, lastPixelInt + ivec2(1, 1));

    vec4 last = mix(
        mix(s00, s10, fract.x),
        mix(s01, s11, fract.x),
        fract.y
    );

  // Neighborhood clamping
    vec3 colorMin = vec3(1e10);
    vec3 colorMax = vec3(-1e10);

    for (int y = -1; y <= 1; y++) {
        for (int x = -1; x <= 1; x++) {
            ivec2 offset = pixel + ivec2(x, y);
            if (offset.x >= 0 && offset.x < resolution.x &&
                offset.y >= 0 && offset.y < resolution.y) {
                vec3 neighborColor = imageLoad(u_thisFrameShaded, offset).rgb;
                colorMin = min(colorMin, neighborColor);
                colorMax = max(colorMax, neighborColor);
            }
        }
    }
    vec3 clampedHistory = clamp(last.rgb, colorMin, colorMax*2);
    // vec3 clampedHistory = last.rgb;
    float depthDifference = abs(last.a - current.a);

    // float blendFactor = 1 - exp(-depthDifference * 20.0);
    float blendFactor = depthDifference < 0.001 ? 0.01 : 0.5;
    blendFactor = clamp(blendFactor, 0.0, 1.0);

    vec3 blendedColor = mix(clampedHistory.rgb, current.rgb,  blendFactor);
    // blendedColor.r = blendFactor;
    // Adaptive blend based on depth difference (simple disocclusion detection)
    vec4 result = vec4(blendedColor, current.a);

    //compute fog
    // float depth = current.a;
    // float fogFactor = exp(-depth );
    // result.rgb = mix(vec3(0.0, 0.0, 0.0), result.rgb, fogFactor);

    imageStore(uColorOutput, pixel, result);
}